# Q1

## Moment Generating Function (MGF) of Bernoulli Distribution

A Bernoulli random variable $X$ takes values $1$ with probability $p$ and $0$ with probability $1-p$. The probability mass function (pmf) is given by:

$$
P(X = x) =
\begin{cases} 
p & \text{if } x = 1, \\
1-p & \text{if } x = 0.
\end{cases}
$$

### Step 1: Derive the MGF

The moment-generating function (MGF), $M_X(t)$, is defined as:

$$
M_X(t) = \mathbb{E}[e^{tX}].
$$

Substitute the pmf of $X$ into the expectation:

$$
M_X(t) = \sum_{x \in \{0, 1\}} e^{tx} P(X = x).
$$

Evaluate the sum:

$$
M_X(t) = e^{t \cdot 0}(1-p) + e^{t \cdot 1}p = (1-p) + pe^t.
$$

Thus, the MGF of a Bernoulli random variable is:

$$
M_X(t) = 1-p + pe^t.
$$

---

### Step 2: Mean of $X$

The mean of $X$, $\mu_X$, is the first moment and is obtained as the first derivative of the MGF evaluated at $t = 0$:

$$
\mu_X = M_X'(t) \Big|_{t=0}.
$$

First, compute the derivative of $M_X(t)$:

$$
M_X'(t) = \frac{d}{dt} \left( 1-p + pe^t \right) = p e^t.
$$

Evaluate at $t = 0$:

$$
\mu_X = M_X'(0) = p e^0 = p.
$$

Thus, the mean of $X$ is:

$$
\mu_X = p.
$$

---

### Step 3: Variance of $X$

The variance of $X$, $\text{Var}(X)$, is computed as:

$$
\text{Var}(X) = M_X''(0) - (M_X'(0))^2.
$$

First, compute the second derivative of $M_X(t)$:

$$
M_X''(t) = \frac{d^2}{dt^2} \left( 1-p + pe^t \right) = \frac{d}{dt}(pe^t) = pe^t.
$$

Evaluate $M_X''(t)$ at $t = 0$:

$$
M_X''(0) = p e^0 = p.
$$

We already computed $M_X'(0) = p$, so:

$$
\text{Var}(X) = M_X''(0) - (M_X'(0))^2 = p - p^2 = p(1-p).
$$

---

# Q2

## Moment Generating Function (MGF) of Exponential Distribution

An exponential random variable $X$ with rate parameter $\lambda > 0$ has the probability density function (PDF):

$$
f_X(x) =
\begin{cases} 
\lambda e^{-\lambda x}, & \text{if } x \geq 0, \\
0, & \text{if } x < 0.
\end{cases}
$$

### Step 1: Derive the MGF

The moment-generating function (MGF), $M_X(t)$, is defined as:

$$
M_X(t) = \mathbb{E}[e^{tX}].
$$

Substitute the definition of expectation for a continuous random variable:

$$
M_X(t) = \int_{-\infty}^\infty e^{tx} f_X(x) \, dx.
$$

For the exponential distribution, the PDF is nonzero only for $x \geq 0$. Substituting the PDF:

$$
M_X(t) = \int_0^\infty e^{tx} \lambda e^{-\lambda x} \, dx.
$$

Simplify the exponent:

$$
M_X(t) = \lambda \int_0^\infty e^{x(t - \lambda)} \, dx.
$$

For the integral to converge, $t < \lambda$ (to ensure $t - \lambda < 0$). Then:

$$
M_X(t) = \lambda \int_0^\infty e^{-x(\lambda - t)} \, dx.
$$

The integral of $e^{-ax}$ is:

$$
\int_0^\infty e^{-ax} \, dx = \frac{1}{a}, \quad \text{for } a > 0.
$$

Substitute $a = \lambda - t$:

$$
M_X(t) = \lambda \cdot \frac{1}{\lambda - t}.
$$

Thus, the MGF of an exponential random variable is:

$$
M_X(t) = \frac{\lambda}{\lambda - t}, \quad \text{for } t < \lambda.
$$

---

### Step 2: Mean of $X$

The mean of $X$, $\mu_X$, is the first moment and is obtained as the first derivative of the MGF evaluated at $t = 0$:

$$
\mu_X = M_X'(t) \Big|_{t=0}.
$$

First, compute the derivative of $M_X(t)$:

$$
M_X(t) = \frac{\lambda}{\lambda - t}.
$$

Differentiate with respect to $t$:

$$
M_X'(t) = \frac{d}{dt} \left( \frac{\lambda}{\lambda - t} \right) = \frac{\lambda}{(\lambda - t)^2}.
$$

Evaluate at $t = 0$:

$$
\mu_X = M_X'(0) = \frac{\lambda}{\lambda^2} = \frac{1}{\lambda}.
$$

Thus, the mean of $X$ is:

$$
\mu_X = \frac{1}{\lambda}.
$$

---

### Step 3: Variance of $X$

The variance of $X$, $\text{Var}(X)$, is computed as:

$$
\text{Var}(X) = M_X''(0) - (M_X'(0))^2.
$$

First, compute the second derivative of $M_X(t)$:

$$
M_X'(t) = \frac{\lambda}{(\lambda - t)^2}.
$$

Differentiate again:

$$
M_X''(t) = \frac{d}{dt} \left( \frac{\lambda}{(\lambda - t)^2} \right) = \frac{2\lambda}{(\lambda - t)^3}.
$$

Evaluate at $t = 0$:

$$
M_X''(0) = \frac{2\lambda}{\lambda^3} = \frac{2}{\lambda^2}.
$$

Now, substitute into the formula for variance:

$$
\text{Var}(X) = M_X''(0) - (M_X'(0))^2 = \frac{2}{\lambda^2} - \left( \frac{1}{\lambda} \right)^2 = \frac{2}{\lambda^2} - \frac{1}{\lambda^2}.
$$

Simplify:

$$
\text{Var}(X) = \frac{1}{\lambda^2}.
$$

---


# Q3

## Moment Generating Function (MGF) of Gamma Distribution

A gamma random variable $X$ with shape parameter $k > 0$ and rate parameter $\lambda > 0$ has the probability density function (PDF):

$$
f_X(x) =
\begin{cases}
\frac{\lambda^k x^{k-1} e^{-\lambda x}}{\Gamma(k)}, & x \geq 0, \\
0, & x < 0,
\end{cases}
$$

where $\Gamma(k)$ is the gamma function, defined as:

$$
\Gamma(k) = \int_0^\infty t^{k-1} e^{-t} \, dt.
$$

---

### Step 1: Derive the MGF

The moment-generating function (MGF), $M_X(t)$, is defined as:

$$
M_X(t) = \mathbb{E}[e^{tX}] = \int_{-\infty}^\infty e^{tx} f_X(x) \, dx.
$$

Substitute the PDF of $X$:

$$
M_X(t) = \int_0^\infty e^{tx} \frac{\lambda^k x^{k-1} e^{-\lambda x}}{\Gamma(k)} \, dx.
$$

Combine the exponential terms:

$$
M_X(t) = \frac{\lambda^k}{\Gamma(k)} \int_0^\infty x^{k-1} e^{-(\lambda - t)x} \, dx, \quad \text{for } t < \lambda.
$$

Recognize the integral as the form of the gamma function:

$$
\int_0^\infty x^{a-1} e^{-bx} \, dx = \frac{\Gamma(a)}{b^a}, \quad b > 0.
$$

Here, $a = k$ and $b = \lambda - t$. Thus:

$$
M_X(t) = \frac{\lambda^k}{\Gamma(k)} \cdot \frac{\Gamma(k)}{(\lambda - t)^k}.
$$

Simplify:

$$
M_X(t) = \left( \frac{\lambda}{\lambda - t} \right)^k, \quad t < \lambda.
$$

Thus, the MGF of a gamma random variable is:

$$
M_X(t) = \left( \frac{\lambda}{\lambda - t} \right)^k, \quad t < \lambda.
$$

---

### Step 2: Mean of $X$

The mean of $X$, $\mu_X$, is the first moment and is obtained as the first derivative of the MGF evaluated at $t = 0$:

$$
\mu_X = M_X'(t) \Big|_{t=0}.
$$

First, compute the derivative of $M_X(t)$:

$$
M_X(t) = \left( \frac{\lambda}{\lambda - t} \right)^k.
$$

Using the chain rule:

$$
M_X'(t) = k \left( \frac{\lambda}{\lambda - t} \right)^{k-1} \cdot \frac{\lambda}{(\lambda - t)^2}.
$$

Evaluate at $t = 0$:

$$
M_X'(0) = k \left( \frac{\lambda}{\lambda} \right)^{k-1} \cdot \frac{\lambda}{\lambda^2} = k \cdot \frac{1}{\lambda}.
$$

Thus, the mean of $X$ is:

$$
\mu_X = \frac{k}{\lambda}.
$$

---

### Step 3: Variance of $X$

The variance of $X$, $\text{Var}(X)$, is computed as:

$$
\text{Var}(X) = M_X''(0) - (M_X'(0))^2.
$$

First, compute the second derivative of $M_X(t)$:

$$
M_X'(t) = k \left( \frac{\lambda}{\lambda - t} \right)^{k-1} \cdot \frac{\lambda}{(\lambda - t)^2}.
$$

Differentiate again:

$$
M_X''(t) = \frac{d}{dt} \left[ k \left( \frac{\lambda}{\lambda - t} \right)^{k-1} \cdot \frac{\lambda}{(\lambda - t)^2} \right].
$$

Using the product and chain rules, we find:

$$
M_X''(t) = k(k-1) \left( \frac{\lambda}{\lambda - t} \right)^{k-2} \cdot \frac{\lambda^2}{(\lambda - t)^4} + k \left( \frac{\lambda}{\lambda - t} \right)^{k-1} \cdot \frac{2\lambda}{(\lambda - t)^3}.
$$

Evaluate $M_X''(t)$ at $t = 0$:

$$
M_X''(0) = k(k-1) \cdot \frac{\lambda^2}{\lambda^4} + k \cdot \frac{2\lambda}{\lambda^3}.
$$

Simplify:

$$
M_X''(0) = \frac{k(k-1)}{\lambda^2} + \frac{2k}{\lambda^2}.
$$

Combine terms:

$$
M_X''(0) = \frac{k^2 + k}{\lambda^2}.
$$

Now compute the variance:

$$
\text{Var}(X) = M_X''(0) - (M_X'(0))^2 = \frac{k^2 + k}{\lambda^2} - \left( \frac{k}{\lambda} \right)^2.
$$

Simplify:

$$
\text{Var}(X) = \frac{k^2 + k}{\lambda^2} - \frac{k^2}{\lambda^2} = \frac{k}{\lambda^2}.
$$

---

