# HW1112 Q7
59. Let X 1 and X 2 be independent standard normal random variables. Show that the
    
joint distribution of

Y 1 = a 11 X 1 + a 12 X 2 + b 1

Y 2 = a 21 X 1 + a 22 X 2 + b 2

is bivariate normal.

![image](https://github.com/HWTeng-Teaching/202409-Math-Stat/blob/main/HW1112/10%20wang/S__1220614_0.jpg)

We are given that \( X_1 \) and \( X_2 \) are independent standard normal random variables, and we want to show that the joint distribution of the random variables

$$
Y_1 = a_{11} X_1 + a_{12} X_2 + b_1
$$
$$
Y_2 = a_{21} X_1 + a_{22} X_2 + b_2
$$

is bivariate normal. To show this, we will use the fact that linear transformations of jointly normal random variables result in a joint normal distribution. Letâ€™s proceed with the proof step by step.

### Step 1: Express \( Y_1 \) and \( Y_2 \) as linear combinations of the standard normal random variables
The variables \( Y_1 \) and \( Y_2 \) are linear combinations of \( X_1 \) and \( X_2 \) plus constants. More specifically, the linear combinations are:

$$
Y_1 = a_{11} X_1 + a_{12} X_2 + b_1
$$
$$
Y_2 = a_{21} X_1 + a_{22} X_2 + b_2
$$

Since \( X_1 \) and \( X_2 \) are independent standard normal random variables, they are jointly normal with a mean of zero and a covariance matrix:

$$
\text{Cov}(X_1, X_2) = \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}
$$

### Step 2: The linear transformation of jointly normal variables is also jointly normal
It is a well-known result that any linear transformation of a vector of jointly normal random variables results in a joint normal distribution. Specifically, if

$$
\begin{pmatrix} Y_1 \\ Y_2 \end{pmatrix} = A \begin{pmatrix} X_1 \\ X_2 \end{pmatrix} + b
$$

where \( A \) is a \( 2 \times 2 \) matrix and \( b \) is a vector of constants, then the random vector \( \begin{pmatrix} Y_1 \\ Y_2 \end{pmatrix} \) is jointly normal. In our case, we have the transformation

$$
\begin{pmatrix} Y_1 \\ Y_2 \end{pmatrix} = \begin{pmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{pmatrix} \begin{pmatrix} X_1 \\ X_2 \end{pmatrix} + \begin{pmatrix} b_1 \\ b_2 \end{pmatrix}
$$

Since \( X_1 \) and \( X_2 \) are independent standard normal random variables, the joint distribution of \( \begin{pmatrix} Y_1 \\ Y_2 \end{pmatrix} \) is bivariate normal.

### Step 3: Calculate the mean and covariance of \( Y_1 \) and \( Y_2 \)
#### Mean:
Since \( X_1 \) and \( X_2 \) have zero means, the mean of \( Y_1 \) and \( Y_2 \) is:

$$
\mathbb{E}[Y_1] = a_{11} \mathbb{E}[X_1] + a_{12} \mathbb{E}[X_2] + b_1 = b_1
$$
$$
\mathbb{E}[Y_2] = a_{21} \mathbb{E}[X_1] + a_{22} \mathbb{E}[X_2] + b_2 = b_2
$$

Thus, the mean vector of \( Y_1 \) and \( Y_2 \) is:

$$
\mu = \begin{pmatrix} b_1 \\ b_2 \end{pmatrix}
$$

#### Covariance:
To compute the covariance matrix of \( Y_1 \) and \( Y_2 \), we need to find the variances and covariances of \( Y_1 \) and \( Y_2 \).

- **Covariance between \( Y_1 \) and \( Y_2 \):**

$$
\text{Cov}(Y_1, Y_2) = \text{Cov}(a_{11} X_1 + a_{12} X_2, a_{21} X_1 + a_{22} X_2)
$$

Using the linearity of covariance and the fact that \( X_1 \) and \( X_2 \) are independent:

$$
\text{Cov}(Y_1, Y_2) = a_{11} a_{21} \text{Cov}(X_1, X_1) + a_{11} a_{22} \text{Cov}(X_1, X_2) + a_{12} a_{21} \text{Cov}(X_2, X_1) + a_{12} a_{22} \text{Cov}(X_2, X_2)
$$

Since \( \text{Cov}(X_1, X_1) = 1 \), \( \text{Cov}(X_1, X_2) = 0 \), and \( \text{Cov}(X_2, X_2) = 1 \), this simplifies to:

$$
\text{Cov}(Y_1, Y_2) = a_{11} a_{21} + a_{12} a_{22}
$$

- **Variance of \( Y_1 \):**

$$
\text{Var}(Y_1) = \text{Var}(a_{11} X_1 + a_{12} X_2) = a_{11}^2 \text{Var}(X_1) + a_{12}^2 \text{Var}(X_2)
$$

Since \( \text{Var}(X_1) = 1 \) and \( \text{Var}(X_2) = 1 \), this simplifies to:

$$
\text{Var}(Y_1) = a_{11}^2 + a_{12}^2
$$

- **Variance of \( Y_2 \):**

$$
\text{Var}(Y_2) = \text{Var}(a_{21} X_1 + a_{22} X_2) = a_{21}^2 \text{Var}(X_1) + a_{22}^2 \text{Var}(X_2)
$$

This simplifies to:

$$
\text{Var}(Y_2) = a_{21}^2 + a_{22}^2
$$

Thus, the covariance matrix of \( Y_1 \) and \( Y_2 \) is:

$$
\Sigma = \begin{pmatrix}
\text{Var}(Y_1) & \text{Cov}(Y_1, Y_2) \\
\text{Cov}(Y_1, Y_2) & \text{Var}(Y_2)
\end{pmatrix}
= \begin{pmatrix}
a_{11}^2 + a_{12}^2 & a_{11} a_{21} + a_{12} a_{22} \\
a_{11} a_{21} + a_{12} a_{22} & a_{21}^2 + a_{22}^2
\end{pmatrix}
$$

### Step 4: Conclusion
Since \( Y_1 \) and \( Y_2 \) are linear transformations of the independent standard normal random variables \( X_1 \) and \( X_2 \), the joint distribution of \( Y_1 \) and \( Y_2 \) is bivariate normal with mean vector:

$$
\mu = \begin{pmatrix} b_1 \\ b_2 \end{pmatrix}
$$

and covariance matrix:

$$
\Sigma = \begin{pmatrix}
a_{11}^2 + a_{12}^2 & a_{11} a_{21} + a_{12} a_{22} \\
a_{11} a_{21} + a_{12} a_{22} & a_{21}^2 + a_{22}^2
\end{pmatrix}
$$

Thus, we have shown that the joint distribution of Y1 and  Y2  is bivariate normal.

Since Y1 , Y2 are linear combinations of the independent normal random variables 

X1 , X2 , and the transformation involves a constant shift and a linear combination, the joint distribution of 

Y1 , Y2 is a bivariate normal distribution.

The reasoning is correct because the transformation involves linear combinations of independent normal variables. The multivariate normal distribution is closed under linear transformations, which guarantees that the joint distribution is indeed bivariate normal, with the mean vector and covariance matrix derived as shown.
